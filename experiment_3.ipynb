{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/dariu/Documents/debiasing_goggle/UvA_FACT2022/decaf/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/c/Users/dariu/Documents/debiasing_goggle/UvA_FACT2022/decaf/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/c/Users/dariu/Documents/debiasing_goggle/UvA_FACT2022/decaf/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from models.DECAF import DECAF\n",
    "from data import DataModule, inject_synth_bias, load_credit, preprocess_credit\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_credit()\n",
    "credit_data = preprocess_credit(df)\n",
    "names = list(credit_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = './cache/'\n",
    "def train_decaf(train_dataset, dag_seed, test_dataset, biased_edges={}, dataset=\"credit\",label=\"approved\", bias=0, h_dim=200, lr=0.5e-3,\n",
    "                batch_size=64, lambda_privacy=0, lambda_gp=10, d_updates=10,\n",
    "                alpha=2, rho=2, weight_decay=1e-2, grad_dag_loss=False, l1_g=0,\n",
    "                l1_W=1e-4, p_gen=-1, use_mask=True, epochs=50, generate_test=False):\n",
    "    model_filename = os.path.join(models_dir, 'decaf_'+dataset+str(bias)+'.pkl')\n",
    "\n",
    "    dm = DataModule(train_dataset.values)\n",
    "    dm_test = DataModule(test_dataset.values)\n",
    "\n",
    "    model = DECAF(\n",
    "        dm.dims[0],\n",
    "        dag_seed=dag_seed,\n",
    "        h_dim=h_dim,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        lambda_privacy=lambda_privacy,\n",
    "        lambda_gp=lambda_gp,\n",
    "        d_updates=d_updates,\n",
    "        alpha=alpha,\n",
    "        rho=rho,\n",
    "        weight_decay=weight_decay,\n",
    "        grad_dag_loss=grad_dag_loss,\n",
    "        l1_g=l1_g,\n",
    "        l1_W=l1_W,\n",
    "        p_gen=p_gen,\n",
    "        use_mask=use_mask,\n",
    "    )\n",
    "    print(\"model name: \",model_filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        model = torch.load(model_filename)\n",
    "    else:\n",
    "        trainer = pl.Trainer(max_epochs=epochs, logger=False)\n",
    "        trainer.fit(model, dm)\n",
    "        torch.save(model, model_filename)\n",
    "\n",
    "    # Generate synthetic data\n",
    "    synth_dataset = (\n",
    "        model.gen_synthetic(\n",
    "            dm.dataset.x,\n",
    "            gen_order=model.get_gen_order(),\n",
    "            biased_edges=biased_edges,\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "    synth_dataset[:, -1] = synth_dataset[:, -1].astype(np.int8)\n",
    "\n",
    "    synth_dataset = pd.DataFrame(synth_dataset,\n",
    "                                 index=train_dataset.index,\n",
    "                                 columns=train_dataset.columns)\n",
    "    synth_dataset[\"ethnicity\"] = np.round(synth_dataset[\"ethnicity\"])\n",
    "\n",
    "    # generate synthetic data of size X_test\n",
    "    if generate_test:\n",
    "        synth_dataset_x_test = (\n",
    "            model.gen_synthetic(\n",
    "                dm_test.dataset.x,\n",
    "                gen_order=model.get_gen_order(),\n",
    "                biased_edges=biased_edges,\n",
    "            )\n",
    "            .detach()\n",
    "            .numpy()\n",
    "        )\n",
    "        synth_dataset_x_test[:, -1] = synth_dataset_x_test[:, -1].astype(np.int8)\n",
    "\n",
    "        synth_dataset_x_test = pd.DataFrame(synth_dataset_x_test,\n",
    "                                    index=test_dataset.index,\n",
    "                                    columns=test_dataset.columns)\n",
    "        synth_dataset_x_test[\"ethnicity\"] = np.round(synth_dataset_x_test[\"ethnicity\"])\n",
    "\n",
    "        return synth_dataset, synth_dataset_x_test\n",
    "\n",
    "    return synth_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dag_seed of paper:  [[1, 7], [6, 15], [6, 3], [8, 10], [8, 15], [8, 9], [13, 3], [12, 3], [11, 9], [5, 9], [5, 3], [7, 10], [10, 15], [10, 2], [9, 4], [9, 2], [9, 12], [2, 14], [3, 15], [14, 15], [14, 3]]\n"
     ]
    }
   ],
   "source": [
    "# Define DAG for Credit dataset\n",
    "credit_dag= [    \n",
    "    # Edges from age\n",
    "    ['age', 'yearsemployed'],\n",
    "    \n",
    "    # Edges from ethnicity\n",
    "    ['ethnicity', 'approved'],\n",
    "    ['ethnicity', 'married'],\n",
    "    \n",
    "    # Edges from default\n",
    "    [\"priordefault\", \"creditscore\"],\n",
    "    [\"priordefault\", \"approved\"],\n",
    "    [\"priordefault\", \"employed\"],\n",
    "    \n",
    "    # Edges from zip\n",
    "    [\"zip\", \"married\"],\n",
    "    # Edges from citizen\n",
    "    [\"citizen\",\"married\"],\n",
    "    # Edges from driverslicense\n",
    "    [\"driverslicense\",\"employed\"],\n",
    "    # Edges from education_level\n",
    "    [\"educationlevel\",\"employed\"],\n",
    "    [\"educationlevel\",\"married\"],\n",
    "    \n",
    "    # Edges from yearsemployed\n",
    "    [\"yearsemployed\", \"creditscore\"],\n",
    "    # Edges from creditscore\n",
    "    [\"creditscore\", \"approved\"],\n",
    "    [\"creditscore\", \"debt\"],\n",
    "    \n",
    "    # Edges from employed\n",
    "    [\"employed\", \"bankcustomer\"],\n",
    "    [\"employed\", \"debt\"],\n",
    "    [\"employed\", \"citizen\"],\n",
    "    \n",
    "    # Edges from debt\n",
    "    [\"debt\", \"income\"],\n",
    "    # Edges from married\n",
    "    [\"married\", \"approved\"],\n",
    "    \n",
    "    # Edges from income\n",
    "    [\"income\", \"approved\"],\n",
    "    [\"income\", \"married\"],\n",
    "]\n",
    "\n",
    "def dag_to_idx(df, dag):\n",
    "    \"\"\"Convert columns in a DAG to the corresponding indices.\"\"\"\n",
    "\n",
    "    dag_idx = []\n",
    "    for edge in dag:\n",
    "        dag_idx.append([df.columns.get_loc(edge[0]), df.columns.get_loc(edge[1])])\n",
    "\n",
    "    return dag_idx\n",
    "\n",
    "#Convert the DAG to one that can be provided to the DECAF model\n",
    "dag_seed_paper = dag_to_idx(credit_data, credit_dag)\n",
    "print(\"dag_seed of paper: \",dag_seed_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias dict ND: {}\n",
      "Bias dict FTU: {15: [6]}\n",
      "Bias dict DP: {15: [3, 6]}\n"
     ]
    }
   ],
   "source": [
    "def create_bias_dict(df, edge_map):\n",
    "    \"\"\"\n",
    "    Convert the given edge tuples to a bias dict used for generating\n",
    "    debiased synthetic data.\n",
    "    \"\"\"\n",
    "    bias_dict = {}\n",
    "    for key, val in edge_map.items():\n",
    "        bias_dict[df.columns.get_loc(key)] = [df.columns.get_loc(f) for f in val]\n",
    "    \n",
    "    return bias_dict\n",
    "\n",
    "bias_dict_nd = {}\n",
    "print('Bias dict ND:', bias_dict_nd)\n",
    "\n",
    "# Bias dictionary to satisfy FTU\n",
    "bias_dict_ftu = create_bias_dict(credit_data, {'approved': ['ethnicity']})\n",
    "print('Bias dict FTU:', bias_dict_ftu)\n",
    "\n",
    "# Bias dictionary to satisfy DP\n",
    "bias_dict_dp = create_bias_dict(credit_data, {'approved': ['married','ethnicity']})\n",
    "print('Bias dict DP:', bias_dict_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised adjacency matrix as parsed:\n",
      " Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "model name:  ./cache/decaf_credit-1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/dariu/Documents/debiasing_goggle/UvA_FACT2022/decaf/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n",
      "/mnt/c/Users/dariu/Documents/debiasing_goggle/UvA_FACT2022/decaf/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:170: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and testing sets\n",
    "X_train, X_test = train_test_split(credit_data, test_size=0.2)            \n",
    "_, X_synth = train_decaf(X_train, dag_seed_paper, X_test, bias=-1, epochs=250, generate_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>debt</th>\n",
       "      <th>married</th>\n",
       "      <th>bankcustomer</th>\n",
       "      <th>educationlevel</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>yearsemployed</th>\n",
       "      <th>priordefault</th>\n",
       "      <th>employed</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>driverslicense</th>\n",
       "      <th>citizen</th>\n",
       "      <th>zip</th>\n",
       "      <th>income</th>\n",
       "      <th>approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.166240</td>\n",
       "      <td>0.697011</td>\n",
       "      <td>0.687802</td>\n",
       "      <td>0.362353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.203573</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>9.961885e-01</td>\n",
       "      <td>4.121422e-06</td>\n",
       "      <td>0.677733</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.296814</td>\n",
       "      <td>0.403299</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.710245</td>\n",
       "      <td>0.651135</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.008544</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>4.226015e-11</td>\n",
       "      <td>6.113227e-06</td>\n",
       "      <td>0.029042</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.986046</td>\n",
       "      <td>0.044959</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>0.686650</td>\n",
       "      <td>0.285029</td>\n",
       "      <td>0.242211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137373</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>9.958941e-01</td>\n",
       "      <td>1.074315e-12</td>\n",
       "      <td>0.047845</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.291636</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.682305</td>\n",
       "      <td>0.276013</td>\n",
       "      <td>0.796807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060315</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>9.955711e-01</td>\n",
       "      <td>1.015533e-10</td>\n",
       "      <td>0.205406</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.296838</td>\n",
       "      <td>0.007145</td>\n",
       "      <td>0.711416</td>\n",
       "      <td>0.299072</td>\n",
       "      <td>0.798134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>1.849099e-01</td>\n",
       "      <td>1.430713e-08</td>\n",
       "      <td>0.680122</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.352864</td>\n",
       "      <td>0.327708</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.257903</td>\n",
       "      <td>0.351548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.065710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>9.957348e-01</td>\n",
       "      <td>3.901292e-02</td>\n",
       "      <td>0.228109</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.474442</td>\n",
       "      <td>0.460031</td>\n",
       "      <td>0.083659</td>\n",
       "      <td>0.706829</td>\n",
       "      <td>0.636795</td>\n",
       "      <td>0.787074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369804</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.065370</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>5.154211e-08</td>\n",
       "      <td>5.206937e-03</td>\n",
       "      <td>0.583997</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.452056</td>\n",
       "      <td>0.108552</td>\n",
       "      <td>0.700555</td>\n",
       "      <td>0.296957</td>\n",
       "      <td>0.402053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>2.474727e-05</td>\n",
       "      <td>3.474187e-13</td>\n",
       "      <td>0.487198</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.285789</td>\n",
       "      <td>0.403353</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.673438</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>0.795446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.435052</td>\n",
       "      <td>0.063813</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>9.956285e-01</td>\n",
       "      <td>1.234888e-10</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.991927</td>\n",
       "      <td>0.178315</td>\n",
       "      <td>0.293606</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.332864</td>\n",
       "      <td>0.798147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093287</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>6.835418e-01</td>\n",
       "      <td>9.440049e-01</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.462891</td>\n",
       "      <td>0.022862</td>\n",
       "      <td>0.674506</td>\n",
       "      <td>0.704022</td>\n",
       "      <td>0.060812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.412260</td>\n",
       "      <td>0.025024</td>\n",
       "      <td>0.055438</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>2.631342e-01</td>\n",
       "      <td>9.404732e-01</td>\n",
       "      <td>0.680783</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.978661</td>\n",
       "      <td>0.454512</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.700185</td>\n",
       "      <td>0.776300</td>\n",
       "      <td>0.763937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105643</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>0.987347</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>9.406369e-10</td>\n",
       "      <td>7.562730e-01</td>\n",
       "      <td>0.681189</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.399928</td>\n",
       "      <td>0.229290</td>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.602667</td>\n",
       "      <td>0.798214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>1.004431e-07</td>\n",
       "      <td>7.100021e-07</td>\n",
       "      <td>0.046477</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.426782</td>\n",
       "      <td>0.048504</td>\n",
       "      <td>0.076720</td>\n",
       "      <td>0.712653</td>\n",
       "      <td>0.617855</td>\n",
       "      <td>0.743427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014820</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>2.984281e-08</td>\n",
       "      <td>2.429245e-12</td>\n",
       "      <td>0.684522</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.999073</td>\n",
       "      <td>0.193601</td>\n",
       "      <td>0.025523</td>\n",
       "      <td>0.703161</td>\n",
       "      <td>0.295394</td>\n",
       "      <td>0.619436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.008939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>9.963960e-01</td>\n",
       "      <td>4.844185e-01</td>\n",
       "      <td>0.030116</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.948563</td>\n",
       "      <td>0.469754</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0.703207</td>\n",
       "      <td>0.575070</td>\n",
       "      <td>0.763256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.058780</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>9.957706e-01</td>\n",
       "      <td>5.507139e-06</td>\n",
       "      <td>0.048169</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         male       age      debt   married  bankcustomer  educationlevel  \\\n",
       "619  0.998504  0.041671  0.166240  0.697011      0.687802        0.362353   \n",
       "463  0.296814  0.403299  0.011599  0.710245      0.651135        0.798047   \n",
       "213  0.986046  0.044959  0.009857  0.686650      0.285029        0.242211   \n",
       "165  0.291636  0.047369  0.005433  0.682305      0.276013        0.796807   \n",
       "2    0.999999  0.296838  0.007145  0.711416      0.299072        0.798134   \n",
       "80   0.999961  0.352864  0.327708  0.681553      0.257903        0.351548   \n",
       "34   0.474442  0.460031  0.083659  0.706829      0.636795        0.787074   \n",
       "42   0.999846  0.452056  0.108552  0.700555      0.296957        0.402053   \n",
       "346  0.285789  0.403353  0.003940  0.673438      0.338430        0.795446   \n",
       "112  0.991927  0.178315  0.293606  0.707005      0.332864        0.798147   \n",
       "491  0.999530  0.462891  0.022862  0.674506      0.704022        0.060812   \n",
       "336  0.978661  0.454512  0.009201  0.700185      0.776300        0.763937   \n",
       "673  0.999999  0.399928  0.229290  0.696469      0.602667        0.798214   \n",
       "522  0.426782  0.048504  0.076720  0.712653      0.617855        0.743427   \n",
       "138  0.999073  0.193601  0.025523  0.703161      0.295394        0.619436   \n",
       "605  0.948563  0.469754  0.011258  0.703207      0.575070        0.763256   \n",
       "\n",
       "     ethnicity  yearsemployed  priordefault  employed  creditscore  \\\n",
       "619        1.0       0.203573      0.008763  1.000000     0.003966   \n",
       "463        1.0       0.000220      0.008544  0.999984     0.000951   \n",
       "213        1.0       0.137373      0.008194  1.000000     0.000153   \n",
       "165        1.0       0.060315      0.010130  1.000000     0.000146   \n",
       "2          1.0       0.001347      0.008120  0.999233     0.000262   \n",
       "80         1.0       0.008755      0.065710  1.000000     0.023908   \n",
       "34         1.0       0.369804      0.009402  0.065370     0.000089   \n",
       "42         1.0       0.007048      0.009820  1.000000     0.008410   \n",
       "346        1.0       0.435052      0.063813  0.999207     0.000156   \n",
       "112        1.0       0.093287      0.008819  1.000000     0.000097   \n",
       "491        1.0       0.412260      0.025024  0.055438     0.005715   \n",
       "336        0.0       0.105643      0.008840  0.987347     0.000689   \n",
       "673        0.0       0.000467      0.008431  1.000000     0.000806   \n",
       "522        1.0       0.014820      0.008942  1.000000     0.008098   \n",
       "138        1.0       0.000412      0.008939  1.000000     0.004788   \n",
       "605        1.0       0.004614      0.009039  0.058780     0.000274   \n",
       "\n",
       "     driverslicense       citizen       zip    income  approved  \n",
       "619    9.961885e-01  4.121422e-06  0.677733  0.002375       1.0  \n",
       "463    4.226015e-11  6.113227e-06  0.029042  0.000277       1.0  \n",
       "213    9.958941e-01  1.074315e-12  0.047845  0.000284       1.0  \n",
       "165    9.955711e-01  1.015533e-10  0.205406  0.001334       1.0  \n",
       "2      1.849099e-01  1.430713e-08  0.680122  0.000992       1.0  \n",
       "80     9.957348e-01  3.901292e-02  0.228109  0.000182       1.0  \n",
       "34     5.154211e-08  5.206937e-03  0.583997  0.000280       1.0  \n",
       "42     2.474727e-05  3.474187e-13  0.487198  0.000159       1.0  \n",
       "346    9.956285e-01  1.234888e-10  0.009736  0.000644       1.0  \n",
       "112    6.835418e-01  9.440049e-01  0.002376  0.000106       1.0  \n",
       "491    2.631342e-01  9.404732e-01  0.680783  0.001705       1.0  \n",
       "336    9.406369e-10  7.562730e-01  0.681189  0.010000       1.0  \n",
       "673    1.004431e-07  7.100021e-07  0.046477  0.003503       1.0  \n",
       "522    2.984281e-08  2.429245e-12  0.684522  0.003682       1.0  \n",
       "138    9.963960e-01  4.844185e-01  0.030116  0.000157       1.0  \n",
       "605    9.957706e-01  5.507139e-06  0.048169  0.001400       1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synth[X_synth['approved'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data due to dependencies\n",
    "X_test.to_csv('x_test_credit.csv')\n",
    "X_synth.to_csv('x_test_synth.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "# synthcity dataloader and evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "from synthcity.metrics import eval_detection, eval_performance, eval_statistical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_synthetic(X_synth, X_test):\n",
    "    quality_evaluator = eval_statistical.AlphaPrecision()\n",
    "    qual_res = quality_evaluator.evaluate(X_test, X_synth)\n",
    "    qual_res = {\n",
    "        k: v for (k, v) in qual_res.items() if \"naive\" in k\n",
    "    }  # use the naive implementation of AlphaPrecision\n",
    "    qual_score = np.mean(list(qual_res.values()))\n",
    "\n",
    "    xgb_evaluator = eval_performance.PerformanceEvaluatorXGB()\n",
    "    linear_evaluator = eval_performance.PerformanceEvaluatorLinear()\n",
    "    mlp_evaluator = eval_performance.PerformanceEvaluatorMLP()\n",
    "    \n",
    "    xgb_score = xgb_evaluator.evaluate(X_test, X_synth)\n",
    "    linear_score = linear_evaluator.evaluate(X_test, X_synth)\n",
    "    mlp_score = mlp_evaluator.evaluate(X_test, X_synth)\n",
    "    gt_perf = (xgb_score[\"gt\"] + linear_score[\"gt\"] + mlp_score[\"gt\"]) / 3\n",
    "\n",
    "    synth_perf = (\n",
    "        xgb_score[\"syn_ood\"] + linear_score[\"syn_ood\"] + mlp_score[\"syn_ood\"]\n",
    "    ) / 3\n",
    "\n",
    "    xgb_detector = eval_detection.SyntheticDetectionXGB()\n",
    "    mlp_detector = eval_detection.SyntheticDetectionMLP()\n",
    "    gmm_detector = eval_detection.SyntheticDetectionGMM()\n",
    "    xgb_det = xgb_detector.evaluate(X_test, X_synth)\n",
    "    mlp_det = mlp_detector.evaluate(X_test, X_synth)\n",
    "    gmm_det = gmm_detector.evaluate(X_test, X_synth)\n",
    "    det_score = (xgb_det[\"mean\"] + mlp_det[\"mean\"] + gmm_det[\"mean\"]) / 3\n",
    "    \n",
    "    return qual_score, (gt_perf, synth_perf), det_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data due to dependency issues\n",
    "X_test = pd.read_csv('x_test_credit.csv', index_col = 0)\n",
    "X_synth_test = pd.read_csv('x_test_synth.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 0.532\n",
      "Detection: 0.725\n",
      "Performance on real: 0.887, on synth: 0.663, diff: 0.224\n"
     ]
    }
   ],
   "source": [
    "label = \"approved\"\n",
    "\n",
    "X_synth_loader = GenericDataLoader(\n",
    "    X_synth_test,\n",
    "    target_column=label,\n",
    ")\n",
    "X_test_loader = GenericDataLoader(\n",
    "    X_test,\n",
    "    target_column=label,\n",
    ")\n",
    "\n",
    "res = evaluate_synthetic(X_synth_loader, X_test_loader)\n",
    "\n",
    "print(f\"Quality: {res[0]:.3f}\")\n",
    "print(f\"Detection: {res[2]:.3f}\")\n",
    "print(\n",
    "    f\"Performance on real: {res[1][0]:.3f}, on synth: {res[1][1]:.3f}, diff: {(res[1][0] - res[1][1]):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goggle_env",
   "language": "python",
   "name": "goggle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
